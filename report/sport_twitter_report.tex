\documentclass{article}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}

\title{Scraping and Classifying Sports Tweets Using Scikit-Learn}
\author{Jazli \& Umair}
\date{December 2022}

\begin{document}

\maketitle
\section{Goal}
The intent of this project is to scrape sports tweets using Twitter's API. Using these tweets we intend to teach a machine learning model to be able to identify the sport a tweet is talking about. Our process is as follows: First we intend to scrape the tweets giving us a large json file. Second, we plan to add another key-value-pair that will contain the actual sport the tweet refers to. This will be done by taking advantage of twitter's context annotations. These context annotations provide insight on the actual sport the tweet is discussing. Next, we will convert the json file into a csv to make the machine learning process easier. Then, we will clean the tweets within the csv using a variety of methods. We will need the data to be split into then training and testing data sets to train our machine learning model. Finally, we will cross validate a couple classifying machine learning models to determine the most appropriate one for our use case.

\section{Methodology}
\begin{enumerate}
    \item Acquiring the Data
    
    We acquired the data using twitters api the code can be found within the TwitterScrape.py. This file is responsible for looking for sports tweets specifically tweets that relate to the following sports: Soccer, Hockey, Basketball, American Football, and Baseball. We scraped 2000 tweets and stored them in the file SportsTweets.json.
    \item Identifying the Sport
    
    Once the tweet data has been saved into a json there is a lot of data that can be used. Our approach for determining the actual sport being discussed was using the context\_annotations field within the json file. This field gives context clues of what the tweet refers to, one of which being sport. We used this field to create a new key value pair that contained the sport. This was done within SportClassification.py.
    \item Converting to CSV
    
    Now that the required information is put into the json file we decided to get rid of the fluff and focus on the important parts of the data. That being the tweet and the sport being discussed. We converted the json file into a csv with only two columns one for the tweet and one for the sport. While converting we also removed any emojis within the tweets.
    \item Data Cleansing
    
    Now that our data was neatly put into a csv file we began cleaning the data. The cleaning operations we decided to perform on the tweets were:
    
    \begin{itemize}
    \item Removing @ handles
    \item Removing hashtags
    \item Removing URLs
    \item Making the tweets lower case
    \item Removing the RT keyword to signify retweets
    \item Removed parentheses, exclamation mark, and question mark
    \item Expanded contractions
    
    \end{itemize}
    
    \item Model Training

    Since we are using Python to train our model on, we decided to use scikit-learn as it is the most intuitive for performing classification tasks as TensorFlow would work better for using neural networks but we wanted to use a more straightforward machine-learning model.
    
    Before creating any models we need to pre-process the data into a format that the model can read. First we had the categorical variable sports where we needed to convert into numeric values. These were encoded using the Label Encoder from scikit-learn's preprocessing library. 
    These are the numbers each correspond to:
    \begin{itemize}
    \item 0: Corresponds to American Football
    \item 1: Corresponds to Baseball
    \item 2: Corresponds to Basketball
    \item 3: Corresponds to Hockey
    \item 4: Corresponds to Soccer
    \end{itemize}

    This label was then assigned to the y/output variable to be observed. 

    In order to analyze these tweets and break them down for the computer to understand we needed to use Natural Langauge Processing or NLP for short.
    We decided to do this using scikit-learn although we realized that TensorFlow, or even PyTorch might be better for this process.

    We decided to use the method TF-IDF for the model to use via the Tfidf Vectorizer given by the scikit's feature extraction library. TF-IDF will find a word's importance to the output then return a weighting factor for each word that appears in its dictionary.
    The "TF" stands for "term frequency" which refers to the frequency of a term in the document. "IDF" refers to the "inverse document frequency" which looks at the logarithmic inverse proportion of documents where the term occurs across the whole corpus. The TFIDF score multiplies both the TF and IDF scores, to get a final weighted value.
    
    It was given the argument (1, 2) for the ngram\_range parameter to allow for the use of n-grams, specifically, unigrams and bigrams when it creates the vector holding the sequences of words.

    Then a variable called X\_fit was created which held the fitted and transformed values from the TfidfVectorizer.

    To find our the best model to be used for this analysis we performed cross validation across five different models and decided to compare their averages. 


    The Stratified K Fold cross validation technique was used to compare these models as it is perceived one of the most accurate k-fold techniques We used 10 folds as the n\_splits parameter since this is generally accepted as the most optimal amount of folds needed for cross validation.

    We tested the Linear SVC model, the RBF Kernel SVM model, the K-Nearest Neighbors model, Logarithmic Regression model, and the Random Forest model using the cross\_val\_score passing in the stratified k fold object which used the training set.

    A function was created to find the highest performing classifier and usually the best performing was the \textbf{Random Forest} model. 

    Afterwards, we decided to fine tune the hyperparameters by using the validation\_curve function to find the best arguments for n\_estimators, max\_depth, max\_samples\_split and finally min\_samples\_leaf to find the best performing values to increase the accuracy of the model.

    \indent For each hyperparameter, we used the validation\_curve function on each and calculated their mean which also used the training set.

    Here is an example of a graph that shows these scores that were assessed for the n\_estimator hyperparameter. The solid blue line at the bottom shows the actual mean score and the outer purple bubble surrounding the line represents the standard deviation that is plus minus from the calculated mean. 

    \includegraphics[scale=.70]{n_estimators.png}

    We then created a new RandomForestClassifier object by passing in the hyperparameters that performed the best in the validation\_curve tests where it was finally used to train itself on the data

    Using that classifier it was then trained on the training data set again but then it was used with the \textbf{untouched testing data set} to generate predictions for the sport corresponding to the tweet.
    
\end{enumerate}
\section{Results}
    To assess the results we used the classification\_report function that compared the predicted sport (output) result of the tweet was to the actual real sport of the tweet.

    A rough average of 83\% was achieved after several tests of the model. 
    

    \includegraphics[scale=1]{classification_report.png}

    To conclude the project, it was an overall success as an accuracy of 83\% is decently accurate for the project.

    Some improvements we could have used was to scrape more tweets in order to create a greater data set for the model to be trained on. Another improvement we could've performed would be to use TensorFlow or PyTorch where the former especially specializes in Neural Networks where this could be used to perform Natural Language Processing better. This could greatly increase the accuracy of the model. A different technique other than TF-IDF could have been used like the bag of words or word2vec technique.

    Future projects we could perform would be to create a model that can formulate a tweet that corresponded to each of those sports maybe via TensorFlow. We could also try to classify tweets of other sports as well. 

\end{document}
